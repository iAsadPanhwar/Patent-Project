{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OKVYQxFYyXb"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gcbgTss4b_Iy",
        "outputId": "b86e014c-0d5a-48d6-8b80-aba59eb3e82a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: crewai==0.76.9 in /usr/local/lib/python3.10/dist-packages (0.76.9)\n",
            "Requirement already satisfied: crewai_tools==0.13.4 in /usr/local/lib/python3.10/dist-packages (0.13.4)\n",
            "Requirement already satisfied: langchain_community==0.3.5 in /usr/local/lib/python3.10/dist-packages (0.3.5)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (1.4.4)\n",
            "Requirement already satisfied: auth0-python>=4.7.1 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (4.7.2)\n",
            "Requirement already satisfied: chromadb>=0.4.24 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (0.5.23)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (8.1.7)\n",
            "Requirement already satisfied: instructor>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (1.7.0)\n",
            "Requirement already satisfied: json-repair>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (0.31.0)\n",
            "Requirement already satisfied: jsonref>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (1.1.0)\n",
            "Requirement already satisfied: langchain>=0.2.16 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (0.3.11)\n",
            "Requirement already satisfied: litellm>=1.44.22 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (1.55.1)\n",
            "Requirement already satisfied: openai>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (1.57.4)\n",
            "Requirement already satisfied: opentelemetry-api>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (1.29.0)\n",
            "Requirement already satisfied: pydantic>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (2.10.3)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (1.0.1)\n",
            "Requirement already satisfied: pyvis>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (0.3.2)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (2024.9.11)\n",
            "Requirement already satisfied: tomli-w>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (1.1.0)\n",
            "Requirement already satisfied: tomli>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (2.2.1)\n",
            "Requirement already satisfied: uv>=0.4.25 in /usr/local/lib/python3.10/dist-packages (from crewai==0.76.9) (0.5.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from crewai_tools==0.13.4) (4.12.3)\n",
            "Requirement already satisfied: docker>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from crewai_tools==0.13.4) (7.1.0)\n",
            "Requirement already satisfied: docx2txt>=0.8 in /usr/local/lib/python3.10/dist-packages (from crewai_tools==0.13.4) (0.8)\n",
            "Requirement already satisfied: embedchain>=0.1.114 in /usr/local/lib/python3.10/dist-packages (from crewai_tools==0.13.4) (0.1.125)\n",
            "Requirement already satisfied: lancedb>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from crewai_tools==0.13.4) (0.17.0)\n",
            "Requirement already satisfied: pyright>=1.1.350 in /usr/local/lib/python3.10/dist-packages (from crewai_tools==0.13.4) (1.1.390)\n",
            "Requirement already satisfied: pytest>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from crewai_tools==0.13.4) (8.3.4)\n",
            "Requirement already satisfied: pytube>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from crewai_tools==0.13.4) (15.0.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from crewai_tools==0.13.4) (2.32.3)\n",
            "Requirement already satisfied: selenium>=4.18.1 in /usr/local/lib/python3.10/dist-packages (from crewai_tools==0.13.4) (4.27.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.3.5) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.3.5) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.3.5) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.3.5) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.3.5) (0.4.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.3.5) (0.3.24)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.3.5) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.3.5) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.3.5) (2.7.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.3.5) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.5) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.5) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.5) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.5) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.5) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.5) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.5) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.5) (1.18.3)\n",
            "Requirement already satisfied: cryptography<44.0.0,>=43.0.1 in /usr/local/lib/python3.10/dist-packages (from auth0-python>=4.7.1->crewai==0.76.9) (43.0.3)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from auth0-python>=4.7.1->crewai==0.76.9) (2.10.1)\n",
            "Requirement already satisfied: urllib3<3.0.0,>=2.0.7 in /usr/local/lib/python3.10/dist-packages (from auth0-python>=4.7.1->crewai==0.76.9) (2.2.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.12.3->crewai_tools==0.13.4) (2.6)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (0.115.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai==0.76.9) (0.32.1)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (3.7.4)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (0.50b0)\n",
            "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (0.20.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (4.66.6)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (1.68.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (31.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (3.10.12)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai==0.76.9) (13.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.5) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.5) (0.9.0)\n",
            "Requirement already satisfied: alembic<2.0.0,>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai_tools==0.13.4) (1.14.0)\n",
            "Requirement already satisfied: cohere<6.0,>=5.3 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai_tools==0.13.4) (5.13.3)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai_tools==0.13.4) (1.73.0)\n",
            "Requirement already satisfied: gptcache<0.2.0,>=0.1.43 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai_tools==0.13.4) (0.1.44)\n",
            "Requirement already satisfied: langchain-cohere<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai_tools==0.13.4) (0.3.3)\n",
            "Requirement already satisfied: langchain-openai<0.3.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai_tools==0.13.4) (0.2.12)\n",
            "Requirement already satisfied: mem0ai<0.2.0,>=0.1.29 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai_tools==0.13.4) (0.1.34)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai_tools==0.13.4) (5.1.0)\n",
            "Requirement already satisfied: pysbd<0.4.0,>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai_tools==0.13.4) (0.3.4)\n",
            "Requirement already satisfied: schema<0.8.0,>=0.7.5 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai_tools==0.13.4) (0.7.7)\n",
            "Requirement already satisfied: tiktoken<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai_tools==0.13.4) (0.7.0)\n",
            "Requirement already satisfied: docstring-parser<0.17,>=0.16 in /usr/local/lib/python3.10/dist-packages (from instructor>=1.3.3->crewai==0.76.9) (0.16)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from instructor>=1.3.3->crewai==0.76.9) (3.1.4)\n",
            "Requirement already satisfied: jiter<0.7,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from instructor>=1.3.3->crewai==0.76.9) (0.6.1)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from instructor>=1.3.3->crewai==0.76.9) (2.27.1)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.10/dist-packages (from lancedb>=0.5.4->crewai_tools==0.13.4) (2.1.0)\n",
            "Requirement already satisfied: pylance==0.20.0 in /usr/local/lib/python3.10/dist-packages (from lancedb>=0.5.4->crewai_tools==0.13.4) (0.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lancedb>=0.5.4->crewai_tools==0.13.4) (24.2)\n",
            "Requirement already satisfied: pyarrow>=14 in /usr/local/lib/python3.10/dist-packages (from pylance==0.20.0->lancedb>=0.5.4->crewai_tools==0.13.4) (17.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.2.16->crewai==0.76.9) (0.3.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_community==0.3.5) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community==0.3.5) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.44.22->crewai==0.76.9) (8.5.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.44.22->crewai==0.76.9) (4.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.13.3->crewai==0.76.9) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.13.3->crewai==0.76.9) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.13.3->crewai==0.76.9) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->crewai==0.76.9) (1.2.15)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai==0.76.9) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai==0.76.9) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai==0.76.9) (1.29.0)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-proto==1.29.0->opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai==0.76.9) (5.29.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk>=1.22.0->crewai==0.76.9) (0.50b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4.2->crewai==0.76.9) (0.7.0)\n",
            "Requirement already satisfied: nodeenv>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pyright>=1.1.350->crewai_tools==0.13.4) (1.9.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=8.0.0->crewai_tools==0.13.4) (1.2.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=8.0.0->crewai_tools==0.13.4) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest>=8.0.0->crewai_tools==0.13.4) (1.5.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis>=0.3.2->crewai==0.76.9) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis>=0.3.2->crewai==0.76.9) (4.0.0)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from pyvis>=0.3.2->crewai==0.76.9) (3.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->crewai_tools==0.13.4) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->crewai_tools==0.13.4) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->crewai_tools==0.13.4) (2024.8.30)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium>=4.18.1->crewai_tools==0.13.4) (0.27.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium>=4.18.1->crewai_tools==0.13.4) (0.11.1)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium>=4.18.1->crewai_tools==0.13.4) (1.8.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community==0.3.5) (3.1.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai_tools==0.13.4) (1.3.8)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb>=0.4.24->crewai==0.76.9) (1.2.0)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai_tools==0.13.4) (1.9.7)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai_tools==0.13.4) (0.9.0)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai_tools==0.13.4) (2.32.0.20241016)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<44.0.0,>=43.0.1->auth0-python>=4.7.1->crewai==0.76.9) (1.17.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.22.0->crewai==0.76.9) (1.17.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb>=0.4.24->crewai==0.76.9) (0.41.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools==0.13.4) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools==0.13.4) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools==0.13.4) (1.25.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools==0.13.4) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools==0.13.4) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools==0.13.4) (1.13.1)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools==0.13.4) (2.0.6)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from gptcache<0.2.0,>=0.1.43->embedchain>=0.1.114->crewai_tools==0.13.4) (5.5.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb>=0.4.24->crewai==0.76.9) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.4.24->crewai==0.76.9) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.44.22->crewai==0.76.9) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai==0.76.9) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai==0.76.9) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai==0.76.9) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai==0.76.9) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai==0.76.9) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai==0.76.9) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai==0.76.9) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai==0.76.9) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai==0.76.9) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai==0.76.9) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.4->instructor>=1.3.3->crewai==0.76.9) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_community==0.3.5) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.22->crewai==0.76.9) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.22->crewai==0.76.9) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.44.22->crewai==0.76.9) (0.22.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai==0.76.9) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai==0.76.9) (2.8.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai==0.76.9) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai==0.76.9) (3.2.2)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai==0.76.9) (0.9)\n",
            "Requirement already satisfied: langchain-experimental<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools==0.13.4) (0.3.3)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools==0.13.4) (2.2.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools==0.13.4) (0.9.0)\n",
            "Requirement already satisfied: pytz<2025.0,>=2024.1 in /usr/local/lib/python3.10/dist-packages (from mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai_tools==0.13.4) (2024.2)\n",
            "Requirement already satisfied: qdrant-client<2.0.0,>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai_tools==0.13.4) (1.12.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.24->crewai==0.76.9) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.24->crewai==0.76.9) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.24->crewai==0.76.9) (1.13.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai==0.76.9) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai==0.76.9) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai==0.76.9) (0.50b0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai==0.76.9) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb>=0.4.24->crewai==0.76.9) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb>=0.4.24->crewai==0.76.9) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb>=0.4.24->crewai==0.76.9) (3.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb>=0.4.24->crewai==0.76.9) (0.26.5)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium>=4.18.1->crewai_tools==0.13.4) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium>=4.18.1->crewai_tools==0.13.4) (1.3.0.post0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium>=4.18.1->crewai_tools==0.13.4) (1.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb>=0.4.24->crewai==0.76.9) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.5) (1.0.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium>=4.18.1->crewai_tools==0.13.4) (1.7.1)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai==0.76.9) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai==0.76.9) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai==0.76.9) (1.0.3)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai==0.76.9) (14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<44.0.0,>=43.0.1->auth0-python>=4.7.1->crewai==0.76.9) (2.22)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools==0.13.4) (1.62.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools==0.13.4) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools==0.13.4) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools==0.13.4) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools==0.13.4) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools==0.13.4) (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb>=0.4.24->crewai==0.76.9) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb>=0.4.24->crewai==0.76.9) (2024.10.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai==0.76.9) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.4.24->crewai==0.76.9) (0.1.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.3->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools==0.13.4) (2024.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai==0.76.9) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai==0.76.9) (0.2.13)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai_tools==0.13.4) (1.68.1)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai_tools==0.13.4) (2.10.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.4.24->crewai==0.76.9) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.4.24->crewai==0.76.9) (1.3.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools==0.13.4) (1.6.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai_tools==0.13.4) (4.1.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai_tools==0.13.4) (0.6.1)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai_tools==0.13.4) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.29->embedchain>=0.1.114->crewai_tools==0.13.4) (4.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install crewai==0.76.9 crewai_tools==0.13.4 langchain_community==0.3.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "iP3Dq4cOBlpw"
      },
      "outputs": [],
      "source": [
        "#!pip install CrewAI crewai_tools langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "Y-XsXo9YCa-C"
      },
      "outputs": [],
      "source": [
        "#!pip install pandas openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltjVe7aCH_VR",
        "outputId": "2c9bc89c-047a-434a-a638-d6746dd63bed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.13.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.3.24)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (9.0.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (2.2.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EwZrSdPed_6M"
      },
      "outputs": [],
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5buKQOIT9ZyO"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from crewai import Agent, Task, Crew, Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "tGt6JOL1UdGr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get('SERPER_API_KEY')\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"placeholder_key\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPEN_AI_API')\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-4o-mini'\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get('SERPER_API_KEY')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ob_a718LsEBh"
      },
      "outputs": [],
      "source": [
        "# from dotenv import load_dotenv\n",
        "# from langchain_groq import ChatGroq\n",
        "\n",
        "# from crewai import LLM\n",
        "\n",
        "# llm = LLM(\n",
        "#     model=\"groq/llama-3.1-8b-instant\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6Nyseb6TcQF"
      },
      "source": [
        "# Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JJwAitztR0zp",
        "outputId": "78ae2fe5-98a9-4ff0-fb84-6f6ba7a817ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "# # Creating tools\n",
        "!pip install requests  # Install the requests library\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sW1LyCBzn2yi"
      },
      "outputs": [],
      "source": [
        "# Patent search tool NEW.\n",
        "\n",
        "import json\n",
        "import os\n",
        "import requests\n",
        "from crewai_tools import BaseTool\n",
        "\n",
        "class PatentSearchTool(BaseTool):\n",
        "    name: str = \"Patent Search tool\"\n",
        "    description: str = \"Search the internet for Patents.\"\n",
        "\n",
        "    # @record_tool(tool_name=\"Patent search tool\")\n",
        "    def _run(self, query: str) -> str:\n",
        "        \"\"\"\n",
        "        Search the internet for Patents.\n",
        "        \"\"\"\n",
        "\n",
        "        url = \"https://google.serper.dev/patents\"\n",
        "\n",
        "        payload = json.dumps({\n",
        "            \"q\": query,\n",
        "            \"num\": 5,\n",
        "            \"autocorrect\": False,\n",
        "            \"tbs\": \"qdr:d\"\n",
        "        })\n",
        "\n",
        "        headers = {\n",
        "            'X-API-KEY': os.getenv('SERPER_API_KEY'),\n",
        "            'Content-Type': 'application/json'\n",
        "        }\n",
        "\n",
        "        response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
        "\n",
        "        # Check if the request was successful (status code 200)\n",
        "        if response.status_code == 200:\n",
        "            # Parse the JSON response\n",
        "            response_data = response.json()\n",
        "\n",
        "            # Log the entire response structure for debugging\n",
        "            print(\"Response data structure:\", json.dumps(response_data, indent=2))\n",
        "\n",
        "            # Ensure 'figures' exists and is a list, and limit to 1 figure\n",
        "            if 'figures' in response_data and isinstance(response_data['figures'], list):\n",
        "                if response_data['figures']:  # Check if the list is not empty\n",
        "                    response_data['figures'] = [response_data['figures'][0]]  # Keep only the first figure\n",
        "                else:\n",
        "                    response_data['figures'] = []  # If no figures, set to an empty list\n",
        "            else:\n",
        "                response_data['figures'] = []  # If 'figures' key does not exist, set to an empty list\n",
        "\n",
        "            # Ensure only one URL and thumbnail, assuming they are nested under 'results' (adjust based on actual API response)\n",
        "            if 'results' in response_data and isinstance(response_data['results'], list) and response_data['results']:\n",
        "                first_result = response_data['results'][0]  # Get the first result only\n",
        "                response_data['results'] = [first_result]  # Replace results with only the first result\n",
        "\n",
        "                # Optionally, if URLs and thumbnails are within each result\n",
        "                if 'url' in first_result:\n",
        "                    first_result['url'] = first_result['url']\n",
        "                if 'thumbnail' in first_result:\n",
        "                    first_result['thumbnail'] = first_result['thumbnail']\n",
        "\n",
        "            # Convert the response data to a JSON string and return\n",
        "            return json.dumps(response_data, indent=2)\n",
        "\n",
        "        # Handle non-200 status code\n",
        "        return f\"Error: Received status code {response.status_code}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pYMHMzjD4oug"
      },
      "outputs": [],
      "source": [
        "# search scholar\n",
        "\n",
        "class ScholarSearchTool(BaseTool):\n",
        "    name: str = \"Scholar search tool\"\n",
        "    description: str = \"Search the internet for academic articles.\"\n",
        "\n",
        "    # @record_tool(tool_name=\"Scholar Search Tool\")\n",
        "    def _run(self, query: str) -> str:\n",
        "        \"\"\"\n",
        "        Search the internet for academic articles.\n",
        "        \"\"\"\n",
        "\n",
        "        url = \"https://google.serper.dev/scholar\"\n",
        "\n",
        "        payload = json.dumps({\n",
        "            \"q\": query,\n",
        "            \"num\": 5,\n",
        "            \"autocorrect\": False,\n",
        "            \"tbs\": \"qdr:d\"\n",
        "        })\n",
        "\n",
        "        headers = {\n",
        "            'X-API-KEY': os.getenv('SERPER_API_KEY'),\n",
        "            'Content-Type': 'application/json'\n",
        "        }\n",
        "\n",
        "        response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
        "\n",
        "        # Check if the request was successful (status code 200)\n",
        "        if response.status_code == 200:\n",
        "            # Parse the JSON response\n",
        "            response_data = response.json()\n",
        "\n",
        "        # Convert the news data back to a JSON string\n",
        "        return json.dumps(response_data, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Z3xwhuvy0m8y"
      },
      "outputs": [],
      "source": [
        "# search news\n",
        "\n",
        "# class NewsSearchTool(BaseTool):\n",
        "#     name: str = \"News search tool\"\n",
        "#     description: str = \"Search the internet for news on the given topic.\"\n",
        "\n",
        "#     # @record_tool(tool_name=\"Scholar Search Tool\")\n",
        "#     def _run(self, query: str) -> str:\n",
        "#         \"\"\"\n",
        "#         Search the internet for news on the given topic.\n",
        "#         \"\"\"\n",
        "\n",
        "#         url = \"https://google.serper.dev/news\"\n",
        "\n",
        "#         payload = json.dumps({\n",
        "#             \"q\": query,\n",
        "#             \"num\": 5,\n",
        "#             \"autocorrect\": False,\n",
        "#             \"tbs\": \"qdr:d\"\n",
        "#         })\n",
        "\n",
        "#         headers = {\n",
        "#             'X-API-KEY': os.getenv('SERPER_API_KEY'),\n",
        "#             'Content-Type': 'application/json'\n",
        "#         }\n",
        "\n",
        "#         response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
        "\n",
        "#         # Check if the request was successful (status code 200)\n",
        "#         if response.status_code == 200:\n",
        "#             # Parse the JSON response\n",
        "#             response_data = response.json()\n",
        "\n",
        "#         # Convert the news data back to a JSON string\n",
        "#         return json.dumps(response_data, indent=2)\n",
        "\n",
        "\n",
        "class NewsSearchTool(BaseTool):\n",
        "    name: str = \"Custom Serper Dev Tool\"\n",
        "    description: str = \"Search the internet for news.\"\n",
        "\n",
        "    # @record_tool(tool_name=\"Custom Serper Dev Tool\")\n",
        "    def _run(self, query: str) -> str:\n",
        "        \"\"\"\n",
        "        Search the internet for news.\n",
        "        \"\"\"\n",
        "\n",
        "        url = \"https://google.serper.dev/news\"\n",
        "\n",
        "        payload = json.dumps({\n",
        "            \"q\": query,\n",
        "            \"num\": 10,\n",
        "            \"autocorrect\": False,\n",
        "            \"tbs\": \"qdr:d\"\n",
        "        })\n",
        "\n",
        "        headers = {\n",
        "            'X-API-KEY': os.getenv('SERPER_API_KEY'),\n",
        "            'Content-Type': 'application/json'\n",
        "        }\n",
        "\n",
        "        response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
        "\n",
        "        # Check if the request was successful (status code 200)\n",
        "        if response.status_code == 200:\n",
        "            # Parse the JSON response\n",
        "            response_data = response.json()\n",
        "\n",
        "            # Log the entire response structure for debugging\n",
        "            print(\"Response data structure:\", json.dumps(response_data, indent=2))\n",
        "\n",
        "            # Ensure 'news' exists and is a list\n",
        "            if 'news' in response_data and isinstance(response_data['news'], list):\n",
        "                if response_data['news']:  # Check if the list is not empty\n",
        "                    response_data['news'] = [response_data['news'][0]]  # Keep only the first news item\n",
        "                else:\n",
        "                    response_data['news'] = []  # If no news items, set to an empty list\n",
        "            else:\n",
        "                response_data['news'] = []  # If 'news' key does not exist, set to an empty list\n",
        "\n",
        "            # Convert the response data to a JSON string\n",
        "            return json.dumps(response_data, indent=2)\n",
        "\n",
        "        # Handle non-200 status code\n",
        "        return f\"Error: Received status code {response.status_code}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ENQuKY7pqQZf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Custom file writer function\n",
        "def write_to_file(content, directory='project', filename='output.txt'):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    file_path = os.path.join(directory, filename)\n",
        "\n",
        "    # Ensure content is a string before writing\n",
        "    if not isinstance(content, str):\n",
        "        content = str(content)\n",
        "\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(content)\n",
        "\n",
        "    print(f\"Content written to {file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SfWdHDNfThtn"
      },
      "outputs": [],
      "source": [
        "from crewai_tools import DirectoryReadTool, \\\n",
        "                         FileReadTool, \\\n",
        "                         SerperDevTool, \\\n",
        "                         DallETool, \\\n",
        "                         ScrapeWebsiteTool, \\\n",
        "                         WebsiteSearchTool, \\\n",
        "                         VisionTool\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nQJ07OVzf31h"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Z9Ofk5xJ0pO_"
      },
      "outputs": [],
      "source": [
        "#Access Google Drive to write files\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gYXyYqRRT7i4"
      },
      "outputs": [],
      "source": [
        "#Reading and writing\n",
        "\n",
        "#read_inputs = DirectoryReadTool(directory='/content/drive/MyDrive/Creative_AI/research_engine/Inputs')\n",
        "#read_outputs = DirectoryReadTool(directory='/content/drive/MyDrive/Creative_AI/research_engine/Outputs')\n",
        "#read_baseline= FileReadTool(file_path='/content/drive/MyDrive/Creative_AI/research_engine/Outputs/knowledge_baseline.txt')\n",
        "#file_read_tool = FileReadTool()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "id": "vxp0wYEHzij6"
      },
      "outputs": [],
      "source": [
        "# Direct file reading using Python standard library\n",
        "#file_path = '/content/drive/MyDrive/Creative_AI/research_engine/Inputs/test.txt'\n",
        "#with open(file_path, 'r') as file:\n",
        "#    content = file.read()\n",
        "\n",
        "#Check if content is being read\n",
        "#print(content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jXOiO9Uc1aw0"
      },
      "outputs": [],
      "source": [
        "#instantiating other tools\n",
        "\n",
        "search_tool = SerperDevTool()\n",
        "scrape_tool = ScrapeWebsiteTool()\n",
        "website_search_tool = WebsiteSearchTool()\n",
        "\n",
        "#vision_tool = VisionTool(model=\"dall-e-3\",\n",
        "#                       size=\"1024x1024\",\n",
        "#                       quality=\"standard\",\n",
        "#                       n=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvXe63584xPr"
      },
      "source": [
        "# AGENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VTLs_sK_cSh-"
      },
      "outputs": [],
      "source": [
        "manager = Agent(\n",
        "    role=\"Project Manager\",\n",
        "    goal=\"Efficiently manage the research team and ensure the production of world-class research reports\",\n",
        "    backstory=(\n",
        "        \"You are a highly experienced research project manager, overseeing a team dedicated to producing exceptional research reports. \"\n",
        "        \"Your responsibilities include ensuring quality at each stage: knowledge collection, analysis, interpretation, and reporting. \"\n",
        "        \"Implement multiple revision loops, verifying each stage for accuracy, completeness, and relevance to the topic, purpose, and context.\"\n",
        "        \"\\n\\nInstructions:\\n\"\n",
        "        \"1. **Knowledge Collection**: Begin by collecting all relevant knowledge on the {topic} within the {context}. Gather only reliable and relevant sources.\\n\"\n",
        "        \"2. **Analysis & Interpretation**: Conduct a detailed analysis, identifying key trends, insights, and implications. Ensure interpretations are accurate and based on the collected data.\\n\"\n",
        "        \"3. **Quality Checks**: After each stage, evaluate completeness, accuracy, and relevance to {purpose}. If content is lacking, instruct the team to revise it accordingly.\\n\"\n",
        "        \"4. **Reporting**: Guide the team in drafting a final report. Structure it clearly with an introduction, analysis, and conclusion sections.\\n\"\n",
        "        \"If any stage is incomplete or fails to meet standards, delegate tasks back to team members for further improvement.\\n\"\n",
        "        \"Research topic: {topic}\\n\"\n",
        "        \"Research purpose: {purpose}\\n\"\n",
        "        \"Research context: {context}\\n\"\n",
        "    ),\n",
        "    # llm=llm,\n",
        "    allow_delegation=True,\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    # max_iter=2,  # Uncomment to limit iterations for efficiency\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_HzMl_4-XbdA"
      },
      "outputs": [],
      "source": [
        "strategist_agent = Agent(\n",
        "    role=\"Strategist\",\n",
        "    goal=\"Analyze and unpack the challenge to reveal its core components and actionable steps\",\n",
        "    backstory=(\n",
        "        \"As an expert strategist, you excel at breaking down complex challenges into clear, manageable elements. \"\n",
        "        \"Your goal is to analyze the challenge thoroughly, identifying core issues, key factors, and any underlying assumptions. \"\n",
        "        \"From this analysis, outline a clear strategy, highlighting priority areas and actionable steps to address the challenge effectively.\"\n",
        "    ),\n",
        "    instructions=(\n",
        "        \"1. **Identify Core Elements**: Begin by identifying and listing the main components of the challenge. \"\n",
        "        \"Break down complex issues into their constituent parts to make them easier to understand.\\n\"\n",
        "        \"2. **Analyze Key Factors**: Examine each core element, identifying any factors that impact the challenge, such as constraints, risks, and opportunities.\\n\"\n",
        "        \"3. **Outline Assumptions**: Highlight any assumptions or uncertainties that might influence the approach to solving the challenge.\\n\"\n",
        "        \"4. **Recommend Actionable Steps**: Conclude by recommending actionable steps based on the analysis, prioritizing actions that are likely to have the highest impact.\\n\"\n",
        "    ),\n",
        "    # llm=llm,\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    # max_iter=2  # Uncomment to limit the iterations for efficiency\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Tmxwqm-GYWaS"
      },
      "outputs": [],
      "source": [
        "researcher_agent = Agent(\n",
        "    role=\"Researcher\",\n",
        "    goal=\"Locate and summarize relevant information to answer questions accurately and comprehensively\",\n",
        "    backstory=(\n",
        "        \"As a diligent and methodical researcher, you are tasked with gathering accessible and highly relevant information \"\n",
        "        \"using the tools available. You excel at sifting through large amounts of information, extracting key points, \"\n",
        "        \"and presenting them concisely.\"\n",
        "        \"\\n\\nInstructions:\\n\"\n",
        "        \"1. **Identify Relevant Sources**: Focus on finding credible and authoritative sources that address the question directly.\\n\"\n",
        "        \"2. **Extract Key Points**: From each source, extract only the most relevant details. Avoid overly general information or unrelated data.\\n\"\n",
        "        \"3. **Summarize Effectively**: Summarize findings in a clear, concise manner. If there are multiple aspects to the question, organize responses by topic.\\n\"\n",
        "        \"4. **Verify for Completeness**: Ensure that all aspects of the question are addressed comprehensively. If a gap remains, indicate further research areas.\\n\"\n",
        "    ),\n",
        "    # llm=llm,\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    # max_iter=4  # Uncomment to limit iterations for efficiency\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "KOYgcTFVtZ83"
      },
      "outputs": [],
      "source": [
        "scraper_agent = Agent(\n",
        "    role=\"Scraper\",\n",
        "    goal=\"Extract and structure key details from patent documents efficiently\",\n",
        "    backstory=(\n",
        "        \"As an expert scraper, you are skilled at extracting and organizing detailed information from patent documents. \"\n",
        "        \"Your role is to retrieve abstracts, claims, technical descriptions, and other relevant information with precision, \"\n",
        "        \"ensuring accuracy for subsequent analysis and reporting.\"\n",
        "    ),\n",
        "    instructions=(\n",
        "        \"1. **Identify Key Sections**: Locate and extract the patent's abstract, claims, and technical descriptions. \"\n",
        "        \"Pay particular attention to details relevant to the invention's novelty, application, and technical aspects.\\n\"\n",
        "        \"2. **Structure Data**: Organize extracted information into a structured format, separating sections such as abstract, claims, inventor information, and classifications.\\n\"\n",
        "        \"3. **Check for Completeness**: Verify that each key section (abstract, claims, and technical descriptions) is captured accurately and is free from omissions.\\n\"\n",
        "        \"4. **Flag Issues**: If any section is missing or lacks clarity, indicate these issues clearly for further review.\\n\"\n",
        "    ),\n",
        "    # llm=llm,\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    # max_iter=2  # Uncomment to limit iterations for efficiency\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GkFE1HR2taqJ"
      },
      "outputs": [],
      "source": [
        "writer_agent = Agent(\n",
        "    role=\"Writer\",\n",
        "    goal=\"Summarize technical information from patents into clear, accessible formats for a broad audience\",\n",
        "    backstory=(\n",
        "        \"As a skilled technical writer, you excel at translating complex technical information from patents into concise and \"\n",
        "        \"understandable summaries. You focus on key innovations, core claims, and potential applications, ensuring that both technical \"\n",
        "        \"and non-technical audiences can grasp the main points effectively.\"\n",
        "    ),\n",
        "    instructions=(\n",
        "        \"1. **Identify Key Innovations**: Begin by summarizing the main innovation of the patent. Focus on what sets it apart and \"\n",
        "        \"why its significant in the field.\\n\"\n",
        "        \"2. **Summarize Core Claims**: Highlight the primary claims, explaining the unique aspects of the invention and any technical advantages.\\n\"\n",
        "        \"3. **Outline Potential Applications**: Describe potential uses and applications of the patent, tailoring language to ensure accessibility for non-technical readers.\\n\"\n",
        "        \"4. **Use Clear, Concise Language**: Avoid overly technical jargon unless absolutely necessary. Where technical terms are used, provide brief clarifications if they might be unfamiliar to general readers.\\n\"\n",
        "        \"5. **Maintain Accuracy and Neutral Tone**: Ensure that summaries remain factual and neutral, focusing on the patent content without adding subjective interpretations.\\n\"\n",
        "    ),\n",
        "    # llm=llm,\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    # max_iter=2  # Uncomment to limit iterations for efficiency\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "VSLzb9DC0-sC"
      },
      "outputs": [],
      "source": [
        "insight_agent = Agent(\n",
        "    role=\"Insight Strategist\",\n",
        "    goal=\"Generate innovative, unexpected insights by applying diverse mental models and angles to the problem\",\n",
        "    backstory=(\n",
        "        \"You are an extremely smart insight strategist with a knack for uncovering unique, out-of-the-box perspectives. \"\n",
        "        \"While you have expertise in the sector of {sector}, you are proficient in integrating knowledge and methodologies from various disciplines. \"\n",
        "        \"You excel at applying creative problem-solving techniques and mental models to generate fresh insights that challenge conventional thinking.\"\n",
        "    ),\n",
        "    instructions=(\n",
        "        \"1. **Analyze from Multiple Angles**: Start by viewing the problem from several distinct perspectives. Apply frameworks from different disciplines (e.g., psychology, economics, history, technology) to uncover novel insights.\\n\"\n",
        "        \"2. **Use Creative Thinking Techniques**: Leverage creativity tools like lateral thinking, mind mapping, or reverse engineering to challenge assumptions and identify unconventional connections.\\n\"\n",
        "        \"3. **Look for Unexpected Connections**: Identify patterns or relationships that might not be immediately obvious. Cross-pollinate ideas from unrelated fields to produce original perspectives.\\n\"\n",
        "        \"4. **Identify Potential Impacts**: For each insight, consider its potential implications. How could it reshape current thinking or lead to unexpected breakthroughs?\\n\"\n",
        "        \"5. **Contextualize with Sector Knowledge**: Use your sector expertise to ground your insights, but don't be afraid to stretch the boundaries and consider cross-industry trends and innovations.\\n\"\n",
        "        \"6. **Encourage Provocative Ideas**: Aim to generate insights that challenge the status quo, provoke thought, and inspire new ways of thinking.\\n\"\n",
        "        \"7. **Keep Insights Actionable**: While creativity is important, ensure that each insight is actionable, offering practical value or guiding strategic decisions.\\n\"\n",
        "    ),\n",
        "    # llm=llm,\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    # max_iter=2  # Uncomment to limit iterations for efficiency\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Agents"
      ],
      "metadata": {
        "id": "Jybo3ZiGGQs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "opportunities_strategist = Agent(\n",
        "    role=\"Opportunities Strategist\",\n",
        "    goal=\"Generate opportunity spaces that address the challenges and situation on the Company\",\n",
        "    backstory=(\n",
        "        \"Based on the insights previously generated, generate five opportunity spaces that address the challenge below based on the specific situation on the company. \"\n",
        "        \"An opportunity space is not a specific solution, but a strategic or tactical direction which could be taken to address the challenge, leveraging the knowledge accrued in the insights.\"\n",
        "    ),\n",
        "    instructions=(\n",
        "        \"1. **Understand the Challenge**: Begin by deeply analyzing the specific challenge faced by the company, considering the context and the nuances of the situation described.\\n\"\n",
        "        \"2. **Leverage Existing Insights**: Use the insights already generated to inform your thinking. These insights should guide your understanding of the company's strengths, weaknesses, and external opportunities.\\n\"\n",
        "        \"3. **Frame Opportunity Spaces**: Create five opportunity spaces, each representing a strategic or tactical direction the company can explore. Avoid specific solutions; focus on broader directions that address the challenge effectively.\\n\"\n",
        "        \"4. **Incorporate Multidisciplinary Frameworks**: Use mental models and frameworks from diverse disciplines such as psychology, technology, and business strategy to ensure a comprehensive perspective.\\n\"\n",
        "        \"5. **Align with Company Goals**: Ensure each opportunity space aligns with the company's mission, values, and overarching objectives.\\n\"\n",
        "        \"6. **Assess Innovation Potential**: Evaluate the potential for innovation in each opportunity space. Identify how it could help the company achieve differentiation or competitive advantage.\\n\"\n",
        "        \"7. **Cross-Functional Considerations**: Analyze how each opportunity space impacts various functions or departments within the company. Highlight synergies or areas requiring alignment.\\n\"\n",
        "        \"8. **Make Actionable Suggestions**: Refine each opportunity space to ensure it is actionable. Clearly define how the company might begin exploring each direction.\"\n",
        "    ),\n",
        "    llm=ChatOpenAI(temperature=0.7, model=\"o1-preview\"),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    # max_iter=2  # Uncomment to limit iterations for efficiency\n",
        ")\n"
      ],
      "metadata": {
        "id": "yPHyi7fMGP9_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import DallETool\n",
        "dalle_tool = DallETool()\n",
        "\n",
        "opp_images = Agent(\n",
        "    role=\"Images Creator\",\n",
        "    goal=\"Generate images based on descriptions\",\n",
        "    backstory=(\n",
        "        \"An AI assistant specialized in creating visual content. Your primary task is to create visually appealing, realistic, and brand-aligned images based on the provided descriptions. \"\n",
        "        \"Each image should reflect the essence of the opportunity space and adhere to the brand's DNA.\"\n",
        "    ),\n",
        "    instructions=(\n",
        "        \"1. **Analyze the Description**: Carefully read and understand the description of each opportunity space and the context provided.\\n\"\n",
        "        \"2. **Maintain Brand Alignment**: Ensure the generated image aligns with the brand's DNA, focusing on elegance, simplicity, and relevance.\\n\"\n",
        "        \"3. **Generate Images**: Use the provided tools to create five images, one for each opportunity space, based on the first idea mentioned.\\n\"\n",
        "        \"4. **Adhere to Contextual Constraints**: Incorporate the sector, target clients, resources, strategic priorities, project name, challenge description, purpose, and focus constraints into the image generation process.\\n\"\n",
        "        \"5. **Ensure Visual Quality**: Each image should be simple, elegant, and essential while staying true to the brand.\"\n",
        "    ),\n",
        "    llm=ChatOpenAI(temperature=0.7, model_name=\"gpt-4-1106-preview\"),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    tools=[dalle_tool]\n",
        ")\n"
      ],
      "metadata": {
        "id": "IDqV_IyxMjwX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent\n",
        "from crewai_tools import CSVSearchTool, DOCXSearchTool, TXTSearchTool\n",
        "\n",
        "doc_analyst = Agent(\n",
        "    role=\"Document Analyzer\",\n",
        "    goal=(\n",
        "        \"1. Analyze the provided documents ({documents}) to extract relevant insights that address the specified challenge.\"\n",
        "        \"2. Focus on identifying actionable information and key elements from the content that could contribute to solving the challenge.\"\n",
        "        \"3. Highlight important details, including direct quotes, references, and their connections to the context outlined below.\"\n",
        "     ),\n",
        "    backstory=(\n",
        "        \"Analyze the attached documents {documents} to identify insights that could be relevant to finding solutions to the challenge below.  Make sure to include direct quotes from the text and references when relevant.\"\n",
        "        \"Output a summary of the content of the document, with particular focus on the elements that could help solve the challenge. If documents {documents} are not attached you should move on.\"\n",
        "\n",
        "            \"Context:\\n\"\n",
        "            \"Sector: {sector}\\n\"\n",
        "            \"Target Clients: {target_clients}\\n\"\n",
        "            \"Resources: {resources}\\n\"\n",
        "            \"Strategic Priorities: {strategic_priorities}\\n\"\n",
        "            \"Project Name: {project_name}\\n\"\n",
        "            \"Challenge Description: {challenge_description}\\n\"\n",
        "            \"Purpose: {purpose}\\n\"\n",
        "            \"Focus Constraints: {focus_constraints}\"\n",
        "\n",
        "    ),\n",
        "    instructions=(\n",
        "        \"1. Carefully review the attached documents ({documents}) and identify insights that are relevant to the challenge.\\n\"\n",
        "        \"2. Summarize the content with a focus on the following contextual elements:\\n\"\n",
        "        \"   - Sector: {sector}\\n\"\n",
        "        \"   - Target Clients: {target_clients}\\n\"\n",
        "        \"   - Resources: {resources}\\n\"\n",
        "        \"   - Strategic Priorities: {strategic_priorities}\\n\"\n",
        "        \"   - Project Name: {project_name}\\n\"\n",
        "        \"   - Challenge Description: {challenge_description}\\n\"\n",
        "        \"   - Purpose: {purpose}\\n\"\n",
        "        \"   - Focus Constraints: {focus_constraints}\\n\"\n",
        "        \"3. Ensure that the summary includes actionable insights, direct quotes, and references to the text when relevant.\\n\"\n",
        "        \"4. If no documents ({documents}) are attached, you may skip this task and move on.\\n\"\n",
        "        \"5. Deliver the summary in a structured format that addresses the purpose of the challenge.\"),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    tools = [CSVSearchTool(),DOCXSearchTool(),TXTSearchTool()]\n",
        ")"
      ],
      "metadata": {
        "id": "tvn37jRBUMgO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7GNV_YWXqO2"
      },
      "source": [
        "# Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "LIQ3AQMLXwhd"
      },
      "outputs": [],
      "source": [
        "generate_queries_task = Task(\n",
        "    description=(\n",
        "        \"Based on the provided challenge (e.g., 'biodegradable packaging for food'), generate a set of five related search keywords \"\n",
        "        \"that are concise, semantically related, and cover possible variations of the original query. \"\n",
        "        \"The queries should be brief and use as few words as possible to maximize relevance and clarity.\\n\\n\"\n",
        "\n",
        "        \"Context:\\n\"\n",
        "        \"Sector: {sector}\\n\"\n",
        "        \"Target Clients: {target_clients}\\n\"\n",
        "        \"Resources: {resources}\\n\"\n",
        "        \"Strategic Priorities: {strategic_priorities}\\n\"\n",
        "        \"Project Name: {project_name}\\n\"\n",
        "        \"Challenge Description: {challenge_description}\\n\"\n",
        "        \"Purpose: {purpose}\\n\"\n",
        "        \"Focus Constraints: {focus_constraints}\\n\\n\"\n",
        "\n",
        "        \"Instructions:\\n\"\n",
        "        \"1. Identify the key concepts in the challenge description.\\n\"\n",
        "        \"2. Generate search queries that reflect these key concepts while considering variations in phrasing, synonyms, or related terms.\\n\"\n",
        "        \"3. Ensure that the queries are concise and directly related to the core aspects of the challenge.\\n\"\n",
        "        \"4. Aim for a balance of broad and specific keywords that would lead to relevant information.\\n\"\n",
        "        \"5. Ensure that each query is distinct but related, to maximize the range of results without redundancy.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A list of five keywords related to the challenge: {challenge_description} that can be used for further searching. \"\n",
        "        \"Example: ['biodegradable food packaging', 'compostable packaging materials', 'eco-friendly packaging for food', 'plant-based packaging for perishables']\"\n",
        "    ),\n",
        "    tools=[],\n",
        "    agent=strategist_agent\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nSezUTBac9_O"
      },
      "outputs": [],
      "source": [
        "patent_search_task = Task(\n",
        "    description=(\n",
        "        \"For each of the queries generated in Task 1, use the search tool to query Google Patents and retrieve \"\n",
        "        \"the top 5 most relevant search results for each query. Ensure that the patents selected are closely related to the original topic, \"\n",
        "        \"focusing on titles, abstracts, and URLs. Avoid extracting image links; only text-based information should be extracted. \"\n",
        "        \"Each query should be treated separately, ensuring the most relevant patents for each search term are identified.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A list of 25 total query results, combining the top 5 relevant patents for each of the 5 queries generated in Task 1. \"\n",
        "        \"Each result should include the title, URL, and abstract, formatted in a tabular structure. Do not include images.\"\n",
        "    ),\n",
        "    tools=[PatentSearchTool()],\n",
        "    agent=researcher_agent\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1-D1Qy1it2AN"
      },
      "outputs": [],
      "source": [
        "scholar_search_task = Task(\n",
        "    description=(\n",
        "        \"For each of the queries generated in Task 1, use the search tool to query Google Scholar and retrieve \"\n",
        "        \"the top 5 most relevant search results for each query. Ensure that the articles selected are closely related to the original topic, \"\n",
        "        \"focusing on titles, abstracts, and URLs. Avoid extracting image links or full-text articles; only text-based information should be extracted. \"\n",
        "        \"Each query should be treated separately to identify the most relevant academic articles for each search term.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A list of 25 total query results, combining the top 5 relevant academic articles for each of the 5 queries generated in Task 1. \"\n",
        "        \"Each result should include the title, URL, and abstract, presented in a tabular format. Do not include images or full-text links.\"\n",
        "    ),\n",
        "    tools=[ScholarSearchTool()],\n",
        "    agent=researcher_agent\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "sLY72c8adyBO"
      },
      "outputs": [],
      "source": [
        "scrape_content_task = Task(\n",
        "    description=(\n",
        "        \"For each of the top 5 patent results obtained in Task 2, use the scrape tool to capture the detailed content from the patent pages. \"\n",
        "        \"Ensure that the abstract, claims, and any relevant technical information are accurately captured for each patent. \"\n",
        "        \"Only extract text-based contentignore images, diagrams, or any non-textual elements. \"\n",
        "        \"The focus should be on key textual information that provides insights into the patents claims, technical details, and innovations.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A collection of the scraped content for each patent, presented in a structured format. \"\n",
        "        \"Each patent should include the abstract, claims, and any important technical details, with the text organized for easy analysis.\"\n",
        "    ),\n",
        "    tools=[scrape_tool],\n",
        "    agent=scraper_agent\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KNBBjKaJNzwn"
      },
      "outputs": [],
      "source": [
        "select_patents_task = Task(\n",
        "    description=(\n",
        "        \"Review all the patents identified in the previous task. For each patent, assess its relevance based on the \"\n",
        "        \"provided context, including the challenge description, sector, target clients, and strategic priorities. \"\n",
        "        \"Use your judgment to determine how closely the patent aligns with the core objectives of the project.\\n\\n\"\n",
        "\n",
        "        \"Context:\\n\"\n",
        "        \"Sector: {sector}\\n\"\n",
        "        \"Target Clients: {target_clients}\\n\"\n",
        "        \"Resources: {resources}\\n\"\n",
        "        \"Strategic Priorities: {strategic_priorities}\\n\"\n",
        "        \"Project Name: {project_name}\\n\"\n",
        "        \"Challenge Description: {challenge_description}\\n\"\n",
        "        \"Purpose: {purpose}\\n\"\n",
        "        \"Focus Constraints: {focus_constraints}\\n\\n\"\n",
        "\n",
        "        \"Instructions:\\n\"\n",
        "        \"1. Review the patents title, abstract, claims, and technical content.\\n\"\n",
        "        \"2. Evaluate how well the patent addresses the key challenges described in the original topic and purpose.\\n\"\n",
        "        \"3. Rank the patents in order of relevance based on how well they align with the projects objectives.\\n\"\n",
        "        \"4. Provide a brief explanation of why each patent was selected, focusing on its relevance to the sector, the challenge, and strategic priorities.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A shortlist of the 10 most relevant patents to the original challenge: {challenge_description}. \"\n",
        "        \"Present a table with the following columns: patent number, title, awardees, URL, a summary of the abstract, and a brief rationale explaining why each patent is relevant.\"\n",
        "    ),\n",
        "    agent=strategist_agent\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "0VnvOMMxuVvA"
      },
      "outputs": [],
      "source": [
        "select_papers_task = Task(\n",
        "    description=(\n",
        "        \"Review all the research papers identified in the previous task. For each paper, assess its relevance based on the \"\n",
        "        \"provided context, including the challenge description, sector, target clients, and strategic priorities. \"\n",
        "        \"Use your judgment to determine how closely the paper aligns with the core objectives of the project.\\n\\n\"\n",
        "\n",
        "        \"Context:\\n\"\n",
        "        \"Sector: {sector}\\n\"\n",
        "        \"Target Clients: {target_clients}\\n\"\n",
        "        \"Resources: {resources}\\n\"\n",
        "        \"Strategic Priorities: {strategic_priorities}\\n\"\n",
        "        \"Project Name: {project_name}\\n\"\n",
        "        \"Challenge Description: {challenge_description}\\n\"\n",
        "        \"Purpose: {purpose}\\n\"\n",
        "        \"Focus Constraints: {focus_constraints}\\n\\n\"\n",
        "\n",
        "        \"Instructions:\\n\"\n",
        "        \"1. Review the papers title, abstract, and key findings.\\n\"\n",
        "        \"2. Evaluate how well the paper addresses the key challenges outlined in the original topic and purpose.\\n\"\n",
        "        \"3. Rank the papers in order of relevance based on how well they align with the projects objectives.\\n\"\n",
        "        \"4. Provide a brief explanation of why each paper was selected, focusing on its relevance to the sector, the challenge, and strategic priorities.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A shortlist of the 10 most relevant papers to the original challenge: {challenge_description}. \"\n",
        "        \"Present a table with the following columns: paper title, authors, URL, summary of the abstract, and a brief rationale explaining why each paper is relevant.\"\n",
        "    ),\n",
        "    agent=strategist_agent\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Ln9seVY6riHC"
      },
      "outputs": [],
      "source": [
        "summarize_task = Task(\n",
        "    description=(\n",
        "        \"Based on the selected content from the previous step, first reproduce the output table from the previous task as it is, \"\n",
        "        \"with the details of the patents and papers.\\n\\n\"\n",
        "\n",
        "        \"Next, write a concise, clear, and comprehensive summary that explains the content of the selected patents and research papers. \"\n",
        "        \"This summary should focus on how these findings relate to the original challenge and purpose. Ensure the summary includes the following:\\n\"\n",
        "        \"1. **Overview of Innovations**: Highlight the key technological innovations found in the papers and patents.\\n\"\n",
        "        \"2. **Research Centers and Trends**: Mention where major research is being conducted, which institutions or industries are leading in this space, and any significant geographical concentrations.\\n\"\n",
        "        \"3. **Research Age and Relevance**: Discuss how recent the research is and whether it's still relevant to the current challenge.\\n\"\n",
        "        \"4. **Technical Details Translation**: Translate technical content into digestible information for a non-technical audience, ensuring clarity and accessibility.\\n\"\n",
        "        \"5. **Relevance to Challenge**: Tie each piece of research to the challenge, explaining how it might contribute to solving the problem at hand.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"Reproduce the output table from the previous task, followed by a clear and concise summary of the patents and papers. \"\n",
        "        \"The summary should cover innovations, research trends, the age of research, and its relevance to the challenge.\"\n",
        "    ),\n",
        "    tools=[],  # Placeholder tool for summarizing content\n",
        "    agent=writer_agent\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "A67EDQIh2d9K"
      },
      "outputs": [],
      "source": [
        "insight_task = Task(\n",
        "    description=(\n",
        "        \"Generate five novel and thought-provoking insights based on the previous research findings, including the patents and research papers. \"\n",
        "        \"An insight should uncover counterintuitive or surprising aspects about the current state of things, often by identifying underlying tensions \"\n",
        "        \"or contradictions in the data. For example, there could be a disconnect between what consumers say they want and what is actually available, \"\n",
        "        \"or conflicting trends that reveal hidden opportunities. Ensure that each insight is original and provides fresh perspectives.\\n\\n\"\n",
        "\n",
        "        \"Example Insights:\\n\"\n",
        "        \"- There is a disconnect between the expert recommendation of intuitive eating and people's ingrained habits of following external food rules, \"\n",
        "        \"relying on data rather than bodily cues.\\n\"\n",
        "        \"- There's a mismatch between peoples desire for natural, whole-food nutrition and the prevalence of artificial supplements in the performance nutrition market.\\n\\n\"\n",
        "\n",
        "        \"Instructions:\\n\"\n",
        "        \"1. **Identify Tensions or Contradictions**: Look for contradictions or tensions in the research that might lead to surprising insights.\\n\"\n",
        "        \"2. **Generate Catchy Titles**: Each insight should have a compelling and catchy title that summarizes the tension or novel idea.\\n\"\n",
        "        \"3. **Provide Context**: After each insight, write a brief description that explains the underlying tension and the implications of the finding.\\n\"\n",
        "        \"4. **Cite Relevant Sources**: Reference the specific papers or patents from previous tasks that support or relate to each insight.\\n\"\n",
        "        \"5. **Explain Relevance to the Company**: For each insight, explain how it could impact the company and the challenge at hand, and why it is important for their strategic priorities.\\n\"\n",
        "        \"6. **Link to Challenge and Strategic Priorities**: Ensure that each insight is directly tied to the challenge, sector, target clients, and strategic priorities of the company.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A set of five novel, insightful, and cleverly formulated insights that address key contradictions or surprising trends in the research. \"\n",
        "        \"Each insight should include a catchy title, a brief description, relevant sources from the research, and an explanation of how it applies to the specific company and its strategic priorities.\"\n",
        "    ),\n",
        "    tools=[],  # Placeholder tool for summarizing content\n",
        "    context=[summarize_task],  # Link to the summary task for prior research context\n",
        "    agent=insight_agent\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New tasks"
      ],
      "metadata": {
        "id": "5KUhb8G4QHJr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "b9MWEQ8furNp"
      },
      "outputs": [],
      "source": [
        "opportunities_task = Task(\n",
        "    description=(\n",
        "        \"Here are a few examples of opportunity spaces that flow from insights, with their title and main ideas list:\"\n",
        "\n",
        "        \"Insight1\"\n",
        "        \"People dont think of financial services as individuals, they think for their whole family. Especially during recessions, people rely more and more on their family network\"\n",
        "        \"Opportunity space 1:\"\n",
        "        \"Family bundling: Seeing the family as a wider financial unit, throughout each stage of life. Helping families maximize collective benefits; facilitating seamless household management; Creating meaningful experiences for younger users\"\n",
        "        \"Ideas:\"\n",
        "        \"Shared Family Dashboard\"\n",
        "        \"Collective Minimal Spending: All family members spending counts towards monthly minimum & cash back points\"\n",
        "        \"Payment Tracker: Keep track of upcoming utility payments and easily request family members to pay.\"\n",
        "        \"Family Goals: Set a real shared family goal (e.g. trip to Thailand) and make the process of saving fun and educational through gamified features.\"\n",
        "        \"Family Financial Education: Fun and interactive course for the whole family, including gamified weekly tasks.\"\n",
        "        \"Family Cards: Branded credit/debit cards with family initials or images.\"\n",
        "\n",
        "        \"Insight 2:\"\n",
        "        \"People look for ways to improve their financial behavior, like saving plans and bargain hunting\"\n",
        "        \"Opportunity space 2:\"\n",
        "        \"Come as you are: we help people hack their daily routine, using behavioral design to nudge users for the optimum when life is up or down. Supporting clients as they develop healthy financial habits; Helping our clients navigate the low moments of life\"\n",
        "        \"Ideas:\"\n",
        "        \"Simulate-it: Personal simulation of loan-repayment program, credit limit, or investment forecasting.\"\n",
        "        \"A message from the future you: Plan ahead for financial security at an older age, taking into account predicted COL & playfully visualising your elderly appearance.\"\n",
        "        \"Round it up: Automatic round-up from every purchase towards a dedicated savings goal (e.g. university tuition)\"\n",
        "        \"A piece of advice: Proactive notifications advising on ways to minimise fees and upgrade terms, based on personal usage data.\"\n",
        "        \"Build a Habit: Compete against yourself by setting personal goals and paying yourself when theyre accomplished.\"\n",
        "        \"Far from the eye: Increase your savings by automatically directing a percentage of your monthly salary to a dedicated savings zone.\"\n",
        "\n",
        "        \"Make sure the opportunity spaces are intriguingly formulated, that they are specific and non-obvious, but also that they encompass a wide range of ways to address the challenge. Make sure that the ideas, while innovative and interesting, stay true to the brand's DNA.\"\n",
        "\n",
        "            \"Context:\\n\"\n",
        "            \"Sector: {sector}\\n\"\n",
        "            \"Target Clients: {target_clients}\\n\"\n",
        "            \"Resources: {resources}\\n\"\n",
        "            \"Strategic Priorities: {strategic_priorities}\\n\"\n",
        "            \"Project Name: {project_name}\\n\"\n",
        "            \"Challenge Description: {challenge_description}\\n\"\n",
        "            \"Purpose: {purpose}\\n\"\n",
        "            \"Focus Constraints: {focus_constraints}\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"Five opportunity spaces, each composed of a catchy title, a short description, a reference to the insights that support it, and a list of five relevant product or service ideas.\"\n",
        "    ),\n",
        "    tools = [],\n",
        "    context = [insight_task],\n",
        "    agent = opportunities_strategist\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "FNxv8aD8BqZr"
      },
      "outputs": [],
      "source": [
        "opp_image_task = Task(\n",
        "    description=(\n",
        "        \"For each of the opportunity spaces, pick the first idea mentioned and generate a simple, realistic, tasteful image of the product described. Make the image simple, elegant and essential.\"\n",
        "        \"Make sure the image stays true to the brand's DNA.\"\n",
        "\n",
        "        \"Context:\\n\"\n",
        "        \"Sector: {sector}\\n\"\n",
        "        \"Target Clients: {target_clients}\\n\"\n",
        "        \"Resources: {resources}\\n\"\n",
        "        \"Strategic Priorities: {strategic_priorities}\\n\"\n",
        "        \"Project Name: {project_name}\\n\"\n",
        "        \"Challenge Description: {challenge_description}\\n\"\n",
        "        \"Purpose: {purpose}\\n\"\n",
        "        \"Focus Constraints: {focus_constraints}\"\n",
        "\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A set of five images, one for each opportunity space\"\n",
        "    ),\n",
        "    tools = [],\n",
        "    context = [opportunities_task],\n",
        "    agent = opp_images\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_analyze_task = Task(\n",
        "    description=(\n",
        "        \"Analyze the attached documents {documents} to identify insights that could be relevant to finding solutions to the challenge below.  Make sure to include direct quotes from the text and references when relevant.\"\n",
        "        \"Output a summary of the content of the document, with particular focus on the elements that could help solve the challenge. If documents {documents} are not attached you should move on.\"\n",
        "\n",
        "            \"Context:\\n\"\n",
        "            \"Sector: {sector}\\n\"\n",
        "            \"Target Clients: {target_clients}\\n\"\n",
        "            \"Resources: {resources}\\n\"\n",
        "            \"Strategic Priorities: {strategic_priorities}\\n\"\n",
        "            \"Project Name: {project_name}\\n\"\n",
        "            \"Challenge Description: {challenge_description}\\n\"\n",
        "            \"Purpose: {purpose}\\n\"\n",
        "            \"Focus Constraints: {focus_constraints}\"\n",
        "      ),\n",
        "    expected_output=(\n",
        "        \"Output a summary of the content of the document, with particular focus on the elements that could help solve the challenge.\"\n",
        "        \"If documents {documents} are not attached you should move on.\"\n",
        "    ),\n",
        "    tools = [],\n",
        "    agent=doc_analyst\n",
        ")\n"
      ],
      "metadata": {
        "id": "TxvAwd4HWrdi"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEsGAgcoZVNp"
      },
      "source": [
        "\n",
        "# Creating crews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "_l71CkXYKosD"
      },
      "outputs": [],
      "source": [
        "#Patents crew\n",
        "\n",
        "patents_crew = Crew(\n",
        "    agents=[\n",
        "        strategist_agent,\n",
        "        researcher_agent,\n",
        "        #scraper_agent,\n",
        "        writer_agent,\n",
        "\n",
        "      ],\n",
        "\n",
        "    tasks=[\n",
        "        generate_queries_task,\n",
        "        patent_search_task,\n",
        "        #patent_search_task,\n",
        "        #scrape_content_task,\n",
        "        select_patents_task,\n",
        "        summarize_task,\n",
        "\n",
        "    ],\n",
        "\n",
        "    #process=Process.hierarchical,\n",
        "    #manager_agent=manager,\n",
        "    #manager_llm=manager_llm,\n",
        "\n",
        "    process=Process.sequential,\n",
        "    #planning=True,\n",
        "    verbose=True,\n",
        "\t  memory=False,\n",
        "    #cache=False,\n",
        "    #share_crew=False,\n",
        "    #output_log_file=\"outputs/content_plan_log.txt\",\n",
        "    #max_rpm=50,\n",
        "    #output_name='patents_output'\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JA20KTBHuq5",
        "outputId": "5eb3e2e1-5b3b-4eee-fafd-8ceb9e04f057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ],
      "source": [
        "#Scholar crew\n",
        "\n",
        "scholar_crew = Crew(\n",
        "    agents=[\n",
        "        strategist_agent,\n",
        "        researcher_agent,\n",
        "        #scraper_agent,\n",
        "        writer_agent,\n",
        "      ],\n",
        "\n",
        "    tasks=[\n",
        "        generate_queries_task,\n",
        "        scholar_search_task,\n",
        "        #patent_search_task,\n",
        "        #scrape_content_task,\n",
        "        select_papers_task,\n",
        "        summarize_task,\n",
        "\n",
        "    ],\n",
        "\n",
        "    #process=Process.hierarchical,\n",
        "    #manager_agent=manager,\n",
        "    #manager_llm=manager_llm,\n",
        "\n",
        "    process=Process.sequential,\n",
        "    #planning=True,\n",
        "    verbose=True,\n",
        "\t  memory=False,\n",
        "    #cache=False,\n",
        "    #share_crew=False,\n",
        "    #output_log_file=\"outputs/content_plan_log.txt\",\n",
        "    #max_rpm=50,\n",
        "    output_name='scholar_output'\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRI4bqKf65tY",
        "outputId": "212a7fb9-f05c-4623-a2dd-b8bcbef48319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ],
      "source": [
        "#Insights crew\n",
        "\n",
        "insights_crew = Crew(\n",
        "    agents=[\n",
        "        doc_analyst,\n",
        "        insight_agent,\n",
        "      ],\n",
        "\n",
        "    tasks=[\n",
        "        doc_analyze_task,\n",
        "        insight_task,\n",
        "\n",
        "    ],\n",
        "\n",
        "    #process=Process.hierarchical,\n",
        "    #manager_agent=manager,\n",
        "    #manager_llm=manager_llm,\n",
        "\n",
        "    process=Process.sequential,\n",
        "    #planning=True,\n",
        "    verbose=True,\n",
        "\t  memory=False,\n",
        "    #cache=False,\n",
        "    #share_crew=False,\n",
        "    #output_log_file=\"outputs/content_plan_log.txt\",\n",
        "    #max_rpm=50,\n",
        "    output_name='insights'\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Crew"
      ],
      "metadata": {
        "id": "4bzADLh2X7T7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Opportunity Space\n",
        "\n",
        "opp_spaces_crew = Crew(\n",
        "    agents=[\n",
        "        opportunities_strategist,\n",
        "      ],\n",
        "\n",
        "    tasks=[\n",
        "        opportunities_task,\n",
        "\n",
        "\n",
        "    ],\n",
        "\n",
        "    #process=Process.hierarchical,\n",
        "    #manager_agent=manager,\n",
        "    #manager_llm=manager_llm,\n",
        "\n",
        "    process=Process.sequential,\n",
        "    #planning=True,\n",
        "    verbose=True,\n",
        "\t  memory=False,\n",
        "    #cache=False,\n",
        "    #share_crew=False,\n",
        "    #output_log_file=\"outputs/content_plan_log.txt\",\n",
        "    #max_rpm=50,\n",
        "    output_name='Opportunity Spaces'\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l44iqbIl7ZDv",
        "outputId": "84b9e1d3-b719-44ff-9dc4-4960ff255267"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opp_images_crew = Crew(\n",
        "    agents=[\n",
        "        opp_images,\n",
        "      ],\n",
        "\n",
        "    tasks=[\n",
        "        opp_image_task,\n",
        "    ],\n",
        "\n",
        "    #process=Process.hierarchical,\n",
        "    #manager_agent=manager,\n",
        "    #manager_llm=manager_llm,\n",
        "\n",
        "    process=Process.sequential,\n",
        "    #planning=True,\n",
        "    verbose=True,\n",
        "\t  memory=False,\n",
        "    #cache=False,\n",
        "    #share_crew=False,\n",
        "    #output_log_file=\"outputs/content_plan_log.txt\",\n",
        "    #max_rpm=50,\n",
        "    output_name='Opportunity Space Images'\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY5T6cgW_hmq",
        "outputId": "b529e002-8e87-44d5-ecc6-8c466591dfc6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJSI3CkPvoca"
      },
      "source": [
        "# Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "-8Dl2UMcINgQ"
      },
      "outputs": [],
      "source": [
        "input_1 = {\n",
        "    # Company inputs\n",
        "    \"company_name\": \"Coffee Bean Technologies\",\n",
        "    \"sector\": \"Coffee Manufacturing\",\n",
        "    \"target_clients\": \"HoReCa and brands who sell coffee\",\n",
        "    \"resources\": \"Coffee plantations, machinery for harvesting, toasting, brewing, packaging; distribution network\",\n",
        "    \"strategic_priorities\": \"Identifying new products to penetrate existing and new markets, particularly companies targeting younger consumers\",\n",
        "\n",
        "    # Project inputs\n",
        "    \"project_name\": \"Coffee Bean Coating Technologies\",\n",
        "    \"challenge_description\": \"Identifying technologies that enable coating coffee beans with a thin layer containing color and nutrients\",\n",
        "    \"purpose\": \"Enriching cofee beans by coating them with colors and nutrients \",\n",
        "    \"focus_constraints\": \" \",\n",
        "\n",
        "}\n",
        "\n",
        "input_2 = {\n",
        "    # Company inputs\n",
        "    \"company_name\": \"Flipper Eyewear\",\n",
        "    \"sector\": \"Consumer Goods / Eyewear\",\n",
        "    \"target_clients\": \"Individuals seeking versatile and sustainable eyewear solutions\",\n",
        "    \"resources\": \"Innovative eyewear designs with interchangeable lenses and clip-on accessories\",\n",
        "    \"strategic_priorities\": \"Enhance product versatility and user convenience; expand market presence; leverage social media\",\n",
        "\n",
        "    # Project inputs\n",
        "    \"project_name\": \"Development of Eco-Friendly Materials for Eyewear\",\n",
        "    \"challenge_description\": \"Develop eco-friendly materials for frames and lenses to meet growing consumer demand for sustainable products\",\n",
        "    \"purpose\": \"Align product offerings with environmental sustainability trends to attract eco-conscious consumers and differentiate the brand in the competitive eyewear market\",\n",
        "    \"focus_constraints\": \"Ensure materials meet durability standards while maintaining affordability\",\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "input_3 = {\n",
        "    # Company inputs\n",
        "    \"company_name\": \"Sammontana\",\n",
        "    \"sector\": \"Food & Beverage / Consumer Packaged Goods\",\n",
        "    \"target_clients\": \"Italian consumers seeking high-quality gelato and bakery products\",\n",
        "    \"resources\": \"Established reputation; advanced production facilities; strong distribution network\",\n",
        "    \"strategic_priorities\": \"Expand product lines to include health-conscious options; enhance brand presence internationally; invest in sustainable production practices\",\n",
        "\n",
        "    # Project inputs\n",
        "    \"project_name\": \"Development of Plant-Based and Low-Sugar Gelato Options\",\n",
        "    \"challenge_description\": \"Develop plant-based and low-sugar gelato options to cater to health-conscious consumers in Italy\",\n",
        "    \"purpose\": \"Maintain authentic taste and texture while using alternative ingredients\",\n",
        "    \"focus_constraints\": \"Ensure new products meet quality standards and appeal to traditional gelato consumers\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqCtS6TV62GQ"
      },
      "source": [
        "# Flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "rOUZiO5-rzQV"
      },
      "outputs": [],
      "source": [
        "from crewai.flow.flow import Flow, start, listen\n",
        "from crewai import Flow\n",
        "from crewai.flow.flow import listen,start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "5v9TGSWZ61cd"
      },
      "outputs": [],
      "source": [
        "# class InsightGen(Flow):\n",
        "#     @start()\n",
        "#     def find_patents(self):\n",
        "#         patents_output = patents_crew.kickoff(inputs=inputs)\n",
        "#         self.state[\"patents_crew_results\"] = patents_output\n",
        "#         return patents_output\n",
        "\n",
        "#     @start()\n",
        "#     def find_scholar(self):\n",
        "#         scholar_output = scholar_crew.kickoff(inputs=inputs)\n",
        "#         self.state[\"scholar_crew_results\"] = scholar_output\n",
        "#         return scholar_output\n",
        "\n",
        "#     @listen(find_patents)\n",
        "#     @listen(find_scholar)\n",
        "#     def generate_insights(self):\n",
        "#         patents_output = self.state[\"patents_crew_results\"]\n",
        "#         scholar_output = self.state[\"scholar_crew_results\"]\n",
        "\n",
        "#         # Combine the outputs into a single dictionary\n",
        "#         combined_output = {\n",
        "#             \"patents\": patents_output,\n",
        "#             \"scholar\": scholar_output\n",
        "#         }\n",
        "\n",
        "#         # Pass the combined output as a single argument\n",
        "#         insights = insights_crew.kickoff(combined_output)\n",
        "#         self.state[\"insights_crews_results\"] = insights\n",
        "#         return insights\n",
        "\n",
        "\n",
        "# class InsightGen(Flow):\n",
        "#     @start()\n",
        "#     def find_patents(self):\n",
        "#         patents_output = patents_crew.kickoff(inputs=inputs)\n",
        "#         self.state[\"patents_crew_results\"] = patents_output\n",
        "#         return patents_output\n",
        "\n",
        "#     @start()\n",
        "#     def find_scholar(self):\n",
        "#         scholar_output = scholar_crew.kickoff(inputs=inputs)\n",
        "#         self.state[\"scholar_crew_results\"] = scholar_output\n",
        "#         return scholar_output\n",
        "\n",
        "#     @listen(find_patents)\n",
        "#     @listen(find_scholar)\n",
        "#     def generate_insights(self):\n",
        "#         patents_output = self.state[\"patents_crew_results\"]\n",
        "#         scholar_output = self.state[\"scholar_crew_results\"]\n",
        "\n",
        "#         # Combine the outputs into a single dictionary\n",
        "#         combined_output = {\n",
        "#             \"patents\": patents_output,\n",
        "#             \"scholar\": scholar_output,\n",
        "#             \"sector\": inputs[\"sector\"], # Added sector to combined_output\n",
        "#             \"target_clients\": inputs[\"target_clients\"],\n",
        "#             \"resources\": inputs[\"resources\"],\n",
        "#             \"strategic_priorities\": inputs[\"strategic_priorities\"],\n",
        "#             \"project_name\": inputs[\"project_name\"],\n",
        "#             \"challenge_description\": inputs[\"challenge_description\"],\n",
        "#             \"purpose\": inputs[\"purpose\"],\n",
        "#             \"focus_constraints\": inputs[\"focus_constraints\"]\n",
        "#         }\n",
        "\n",
        "#         # Pass the combined output as a single argument\n",
        "#         insights = insights_crew.kickoff(combined_output)\n",
        "#         self.state[\"insights_crews_results\"] = insights\n",
        "#         return insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "QeTRcwnRTLX5"
      },
      "outputs": [],
      "source": [
        "# class InsightGen(Flow):\n",
        "#     @start()\n",
        "#     async def start_parallel_execution(self):\n",
        "#         patents_future = patents_crew.kickoff_async(inputs=input_3)\n",
        "#         scholar_future = scholar_crew.kickoff_async(inputs=input_3)\n",
        "\n",
        "#         patents_output, scholar_output = await asyncio.gather(patents_future, scholar_future)\n",
        "\n",
        "#         # Extract raw output from CrewOutput objects\n",
        "#         patents_data = patents_output.raw_output if hasattr(patents_output, 'raw_output') else str(patents_output)\n",
        "#         scholar_data = scholar_output.raw_output if hasattr(scholar_output, 'raw_output') else str(scholar_output)\n",
        "\n",
        "#         self.state[\"patents_crew_results\"] = patents_data\n",
        "#         self.state[\"scholar_crew_results\"] = scholar_data\n",
        "#         return {\"patents\": patents_data, \"scholar\": scholar_data}\n",
        "\n",
        "#     @listen(start_parallel_execution)\n",
        "#     def generate_insights(self, parallel_results):\n",
        "#         combined_output = {\n",
        "#             **parallel_results,\n",
        "#             \"sector\": input_3[\"sector\"],\n",
        "#             \"target_clients\": input_3[\"target_clients\"],\n",
        "#             \"resources\": input_3[\"resources\"],\n",
        "#             \"strategic_priorities\": input_3[\"strategic_priorities\"],\n",
        "#             \"project_name\": input_3[\"project_name\"],\n",
        "#             \"challenge_description\": input_3[\"challenge_description\"],\n",
        "#             \"purpose\": input_3[\"purpose\"],\n",
        "#             \"focus_constraints\": input_3[\"focus_constraints\"]\n",
        "#         }\n",
        "\n",
        "#         insights = insights_crew.kickoff(combined_output)\n",
        "\n",
        "#         # Extract raw output from CrewOutput\n",
        "#         insights_data = insights.raw_output if hasattr(insights, 'raw_output') else str(insights)\n",
        "\n",
        "#         self.state[\"insights_crews_results\"] = insights_data\n",
        "#         return insights_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class InsightGen(Flow):\n",
        "    @start()\n",
        "    async def start_parallel_execution(self):\n",
        "        patents_future = patents_crew.kickoff_async(inputs=input_3)\n",
        "        scholar_future = scholar_crew.kickoff_async(inputs=input_3)\n",
        "\n",
        "        patents_output, scholar_output = await asyncio.gather(patents_future, scholar_future)\n",
        "\n",
        "        # Extract raw output from CrewOutput objects\n",
        "        patents_data = patents_output.raw_output if hasattr(patents_output, 'raw_output') else str(patents_output)\n",
        "        scholar_data = scholar_output.raw_output if hasattr(scholar_output, 'raw_output') else str(scholar_output)\n",
        "\n",
        "        self.state[\"patents_crew_results\"] = patents_data\n",
        "        self.state[\"scholar_crew_results\"] = scholar_data\n",
        "        return {\"patents\": patents_data, \"scholar\": scholar_data}\n",
        "\n",
        "    @listen(start_parallel_execution)\n",
        "    def generate_insights(self, parallel_results):\n",
        "        combined_output = {\n",
        "            **parallel_results,\n",
        "            \"sector\": input_3[\"sector\"],\n",
        "            \"target_clients\": input_3[\"target_clients\"],\n",
        "            \"resources\": input_3[\"resources\"],\n",
        "            \"strategic_priorities\": input_3[\"strategic_priorities\"],\n",
        "            \"project_name\": input_3[\"project_name\"],\n",
        "            \"challenge_description\": input_3[\"challenge_description\"],\n",
        "            \"purpose\": input_3[\"purpose\"],\n",
        "            \"focus_constraints\": input_3[\"focus_constraints\"]\n",
        "        }\n",
        "\n",
        "        insights_data = insights_crew.kickoff(combined_output)\n",
        "\n",
        "        # Extract raw output from CrewOutput\n",
        "        insights_data = insights_data.raw_output if hasattr(insights_data, 'raw_output') else str(insights_data)\n",
        "\n",
        "        self.state[\"insights_crews_results\"] = insights_data\n",
        "\n",
        "        return insights_data\n",
        "\n",
        "\n",
        "    @listen(generate_insights)\n",
        "    async def generate_opportunity_spaces(self, insights_data):\n",
        "        opp_spaces_input = {\n",
        "            \"insights\": insights_data,\n",
        "            \"sector\": input_3[\"sector\"],\n",
        "            \"target_clients\": input_3[\"target_clients\"],\n",
        "            \"resources\": input_3[\"resources\"],\n",
        "            \"strategic_priorities\": input_3[\"strategic_priorities\"],\n",
        "            \"project_name\": input_3[\"project_name\"],\n",
        "            \"challenge_description\": input_3[\"challenge_description\"],\n",
        "            \"purpose\": input_3[\"purpose\"],\n",
        "            \"focus_constraints\": input_3[\"focus_constraints\"]\n",
        "        }\n",
        "\n",
        "        opp_spaces_output = opp_spaces_crew.kickoff(opp_spaces_input)\n",
        "\n",
        "        opp_spaces_data = opp_spaces_output.raw_output if hasattr(opp_spaces_output, 'raw_output') else str(opp_spaces_output)\n",
        "\n",
        "        self.state[\"opp_spaces_results\"] = opp_spaces_data\n",
        "        return {\n",
        "            \"insights_data\": insights_data,\n",
        "            \"opp_spaces_data\": opp_spaces_data\n",
        "        }\n",
        "\n",
        "\n",
        "    async def kickoff_async(self):\n",
        "        result = await super().kickoff_async()\n",
        "        return result\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YdS2536USyMx"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class InsightGen(Flow):\n",
        "#     @start()\n",
        "#     async def start_parallel_execution(self):\n",
        "#         patents_future = patents_crew.kickoff_async(inputs=input_3)\n",
        "#         scholar_future = scholar_crew.kickoff_async(inputs=input_3)\n",
        "\n",
        "#         patents_output, scholar_output = await asyncio.gather(patents_future, scholar_future)\n",
        "\n",
        "#         # Extract raw output from CrewOutput objects\n",
        "#         patents_data = patents_output.raw_output if hasattr(patents_output, 'raw_output') else str(patents_output)\n",
        "#         scholar_data = scholar_output.raw_output if hasattr(scholar_output, 'raw_output') else str(scholar_output)\n",
        "\n",
        "#         self.state[\"patents_crew_results\"] = patents_data\n",
        "#         self.state[\"scholar_crew_results\"] = scholar_data\n",
        "#         return {\"patents\": patents_data, \"scholar\": scholar_data}\n",
        "\n",
        "#     @listen(start_parallel_execution)\n",
        "#     def generate_insights(self, parallel_results):\n",
        "#         combined_output = {\n",
        "#             **parallel_results,\n",
        "#             \"sector\": input_3[\"sector\"],\n",
        "#             \"target_clients\": input_3[\"target_clients\"],\n",
        "#             \"resources\": input_3[\"resources\"],\n",
        "#             \"strategic_priorities\": input_3[\"strategic_priorities\"],\n",
        "#             \"project_name\": input_3[\"project_name\"],\n",
        "#             \"challenge_description\": input_3[\"challenge_description\"],\n",
        "#             \"purpose\": input_3[\"purpose\"],\n",
        "#             \"focus_constraints\": input_3[\"focus_constraints\"]\n",
        "#         }\n",
        "\n",
        "#         insights_data = insights_crew.kickoff(combined_output)\n",
        "\n",
        "#         # Extract raw output from CrewOutput\n",
        "#         insights_data = insights_data.raw_output if hasattr(insights_data, 'raw_output') else str(insights_data)\n",
        "\n",
        "#         self.state[\"insights_crews_results\"] = insights_data\n",
        "\n",
        "#         return insights_data\n",
        "\n",
        "\n",
        "#     @listen(generate_insights)\n",
        "#     async def generate_opportunity_spaces(self, insights_data):\n",
        "#         opp_spaces_input = {\n",
        "#             \"insights\": insights_data,\n",
        "#             \"sector\": input_3[\"sector\"],\n",
        "#             \"target_clients\": input_3[\"target_clients\"],\n",
        "#             \"resources\": input_3[\"resources\"],\n",
        "#             \"strategic_priorities\": input_3[\"strategic_priorities\"],\n",
        "#             \"project_name\": input_3[\"project_name\"],\n",
        "#             \"challenge_description\": input_3[\"challenge_description\"],\n",
        "#             \"purpose\": input_3[\"purpose\"],\n",
        "#             \"focus_constraints\": input_3[\"focus_constraints\"]\n",
        "#         }\n",
        "\n",
        "#         opp_spaces_output = opp_spaces_crew.kickoff(opp_spaces_input)\n",
        "\n",
        "#         opp_spaces_data = opp_spaces_output.raw_output if hasattr(opp_spaces_output, 'raw_output') else str(opp_spaces_output)\n",
        "\n",
        "#         self.state[\"opp_spaces_results\"] = opp_spaces_data\n",
        "#         return opp_spaces_data\n",
        "\n",
        "#     @listen(generate_opportunity_spaces)\n",
        "#     async def generate_opportunity_images(self, opp_spaces_data,insights_data):\n",
        "#         opp_images_input = {\n",
        "#             \"opportunity_space\": opp_spaces_data,\n",
        "#             \"sector\": input_3[\"sector\"],\n",
        "#             \"target_clients\": input_3[\"target_clients\"],\n",
        "#             \"resources\": input_3[\"resources\"],\n",
        "#             \"strategic_priorities\": input_3[\"strategic_priorities\"],\n",
        "#             \"project_name\": input_3[\"project_name\"],\n",
        "#             \"challenge_description\": input_3[\"challenge_description\"],\n",
        "#             \"purpose\": input_3[\"purpose\"],\n",
        "#             \"focus_constraints\": input_3[\"focus_constraints\"]\n",
        "#         }\n",
        "\n",
        "#         opp_images_output = opp_images_crew.kickoff(opp_images_input)\n",
        "\n",
        "#         opp_images_data = opp_images_output.raw_output if hasattr(opp_images_output, 'raw_output') else str(opp_images_output)\n",
        "\n",
        "#         self.state[\"opp_images_results\"] = opp_images_data\n",
        "\n",
        "#         return {\n",
        "#             \"insights_data\": insights_data,\n",
        "#             \"opp_spaces_data\": opp_spaces_data,\n",
        "#             \"opp_images_\": opp_images_data\n",
        "#         }\n",
        "\n",
        "#     async def kickoff_async(self):\n",
        "#         result = await super().kickoff_async()\n",
        "#         return result\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FrN3J7VShHuD"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "rseWP6eouIqR"
      },
      "outputs": [],
      "source": [
        "flow = InsightGen()\n",
        "# opp_space_flow = OpportunitySpaceGen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "eO5D5Az53i71",
        "outputId": "c84c0108-fb58-4d74-dfb6-b39d444b6ef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plot saved as crewai_flow.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x78658a12df00>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"150%\"\n",
              "            height=\"600\"\n",
              "            src=\"./crewai_flow.html\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "flow.plot()\n",
        "\n",
        "from IPython.display import IFrame\n",
        "\n",
        "IFrame(src='./crewai_flow.html', width='150%', height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Mq7mNN9Koex"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_A9vfNI2ols"
      },
      "source": [
        "# Run Crews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "x9cIVZRTQh35"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "\n",
        "async def run_flow():\n",
        "  \"\"\"Helper function to run the flow using the existing loop.\"\"\"\n",
        "  return await flow.kickoff_async()\n",
        "\n",
        "# Get the current event loop or create a new one if it doesn't exist.\n",
        "loop = asyncio.get_event_loop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7TDZ_M8bLMUg",
        "outputId": "a05cddb3-de64-4c2b-e88e-71b15a2199ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mStrategist\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mBased on the provided challenge (e.g., 'biodegradable packaging for food'), generate a set of five related search keywords that are concise, semantically related, and cover possible variations of the original query. The queries should be brief and use as few words as possible to maximize relevance and clarity.\n",
            "\n",
            "Context:\n",
            "Sector: Food & Beverage / Consumer Packaged Goods\n",
            "Target Clients: Italian consumers seeking high-quality gelato and bakery products\n",
            "Resources: Established reputation; advanced production facilities; strong distribution network\n",
            "Strategic Priorities: Expand product lines to include health-conscious options; enhance brand presence internationally; invest in sustainable production practices\n",
            "Project Name: Development of Plant-Based and Low-Sugar Gelato Options\n",
            "Challenge Description: Develop plant-based and low-sugar gelato options to cater to health-conscious consumers in Italy\n",
            "Purpose: Maintain authentic taste and texture while using alternative ingredients\n",
            "Focus Constraints: Ensure new products meet quality standards and appeal to traditional gelato consumers\n",
            "\n",
            "Instructions:\n",
            "1. Identify the key concepts in the challenge description.\n",
            "2. Generate search queries that reflect these key concepts while considering variations in phrasing, synonyms, or related terms.\n",
            "3. Ensure that the queries are concise and directly related to the core aspects of the challenge.\n",
            "4. Aim for a balance of broad and specific keywords that would lead to relevant information.\n",
            "5. Ensure that each query is distinct but related, to maximize the range of results without redundancy.\u001b[00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:LiteLLM call failed: litellm.AuthenticationError: AuthenticationError: OpenAIException - Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************_6oA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
            "ERROR:root:LiteLLM call failed: litellm.AuthenticationError: AuthenticationError: OpenAIException - Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************_6oA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
            "ERROR:root:LiteLLM call failed: litellm.AuthenticationError: AuthenticationError: OpenAIException - Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************_6oA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
            "ERROR:root:LiteLLM call failed: litellm.AuthenticationError: AuthenticationError: OpenAIException - Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************_6oA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mStrategist\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mBased on the provided challenge (e.g., 'biodegradable packaging for food'), generate a set of five related search keywords that are concise, semantically related, and cover possible variations of the original query. The queries should be brief and use as few words as possible to maximize relevance and clarity.\n",
            "\n",
            "Context:\n",
            "Sector: Food & Beverage / Consumer Packaged Goods\n",
            "Target Clients: Italian consumers seeking high-quality gelato and bakery products\n",
            "Resources: Established reputation; advanced production facilities; strong distribution network\n",
            "Strategic Priorities: Expand product lines to include health-conscious options; enhance brand presence internationally; invest in sustainable production practices\n",
            "Project Name: Development of Plant-Based and Low-Sugar Gelato Options\n",
            "Challenge Description: Develop plant-based and low-sugar gelato options to cater to health-conscious consumers in Italy\n",
            "Purpose: Maintain authentic taste and texture while using alternative ingredients\n",
            "Focus Constraints: Ensure new products meet quality standards and appeal to traditional gelato consumers\n",
            "\n",
            "Instructions:\n",
            "1. Identify the key concepts in the challenge description.\n",
            "2. Generate search queries that reflect these key concepts while considering variations in phrasing, synonyms, or related terms.\n",
            "3. Ensure that the queries are concise and directly related to the core aspects of the challenge.\n",
            "4. Aim for a balance of broad and specific keywords that would lead to relevant information.\n",
            "5. Ensure that each query is distinct but related, to maximize the range of results without redundancy.\u001b[00m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "litellm.AuthenticationError: AuthenticationError: OpenAIException - Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************_6oA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/llms/openai/openai.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    601\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenAIError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/llms/openai/openai.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m                         headers, response = (\n\u001b[0;32m--> 538\u001b[0;31m                             self.make_sync_openai_chat_completion_request(\n\u001b[0m\u001b[1;32m    539\u001b[0m                                 \u001b[0mopenai_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopenai_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/llms/openai/openai.py\u001b[0m in \u001b[0;36mmake_sync_openai_chat_completion_request\u001b[0;34m(self, openai_client, data, timeout)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/llms/openai/openai.py\u001b[0m in \u001b[0;36mmake_sync_openai_chat_completion_request\u001b[0;34m(self, openai_client, data, timeout)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             raw_response = openai_client.chat.completions.with_raw_response.create(\n\u001b[0m\u001b[1;32m    387\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_legacy_response.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLegacyAPIResponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1279\u001b[0m         )\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    958\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************_6oA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1594\u001b[0m                 )\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1567\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m                 response = openai_chat_completions.completion(\n\u001b[0m\u001b[1;32m   1569\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/llms/openai/openai.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    611\u001b[0m                 \u001b[0merror_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    613\u001b[0m                 \u001b[0mstatus_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOpenAIError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************_6oA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-3a5e2fe55653>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkickoff_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#should be await flow.kickoff()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-63a508198d7e>\u001b[0m in \u001b[0;36mkickoff_async\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkickoff_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkickoff_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/flow/flow.py\u001b[0m in \u001b[0;36mkickoff_async\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m# Run all start methods concurrently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# Return the final output (from the last executed method)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/flow/flow.py\u001b[0m in \u001b[0;36m_execute_start_method\u001b[0;34m(self, start_method_name)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_execute_start_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         result = await self._execute_method(\n\u001b[0m\u001b[1;32m    222\u001b[0m             \u001b[0mstart_method_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_methods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_method_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/flow/flow.py\u001b[0m in \u001b[0;36m_execute_method\u001b[0;34m(self, method_name, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m     ) -> Any:\n\u001b[1;32m    229\u001b[0m         result = (\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0;32mawait\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miscoroutinefunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-63a508198d7e>\u001b[0m in \u001b[0;36mstart_parallel_execution\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mscholar_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscholar_crew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkickoff_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpatents_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscholar_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatents_future\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscholar_future\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Extract raw output from CrewOutput objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36mkickoff_async\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkickoff_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;34m\"\"\"Asynchronous kickoff method to start the crew execution.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkickoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkickoff_for_each_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCrewOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/threads.py\u001b[0m in \u001b[0;36mto_thread\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontextvars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfunc_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_in_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36mkickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchical\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;34m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_execute_tasks\u001b[0;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 task_output = task.execute_sync(\n\u001b[0m\u001b[1;32m    697\u001b[0m                     \u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent_to_use\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                     \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36mexecute_sync\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    189\u001b[0m     ) -> TaskOutput:\n\u001b[1;32m    190\u001b[0m         \u001b[0;34m\"\"\"Execute the task synchronously.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36m_execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_by_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         result = agent.execute_task(\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_times_executed\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retry_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_rpm\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rpm_controller\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_times_executed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_times_executed\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retry_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             result = self.agent_executor.invoke(\n\u001b[0m\u001b[1;32m    237\u001b[0m                 {\n\u001b[1;32m    238\u001b[0m                     \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtask_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask_for_human_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ask_for_human_input\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mformatted_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask_for_human_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self, formatted_answer)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_answer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_answer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self, formatted_answer)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_within_rpm_limit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_within_rpm_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                     answer = self.llm.call(\n\u001b[0m\u001b[1;32m    116\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/llm.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, messages, callbacks)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"choices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"message\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    981\u001b[0m                     \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                 )  # DO NOT MAKE THREADED - router retry fallback relies on this!\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    862\u001b[0m                     \u001b[0mprint_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error while checking max token limit: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;31m# MODEL CALL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"stream\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   2949\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2950\u001b[0m         \u001b[0;31m## Map to OpenAI Exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2951\u001b[0;31m         raise exception_type(\n\u001b[0m\u001b[1;32m   2952\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2953\u001b[0m             \u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\u001b[0m in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   2139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexception_mapping_worked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2140\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"litellm_response_headers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitellm_response_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2141\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2142\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2143\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0merror_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLITELLM_EXCEPTION_TYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\u001b[0m in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m401\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                         \u001b[0mexception_mapping_worked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                         raise AuthenticationError(\n\u001b[0m\u001b[1;32m    348\u001b[0m                             \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"AuthenticationError: {exception_provider} - {message}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                             \u001b[0mllm_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: litellm.AuthenticationError: AuthenticationError: OpenAIException - Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************_6oA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ],
      "source": [
        "result = await flow.kickoff_async() #should be await flow.kickoff()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "J1NCt5DIDitj",
        "outputId": "27908e7f-77ac-4b23-e8d0-d74185124806"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'result' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-0ac921c19f1a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"insights\":result,\n",
        "          \"sector\": input_3[\"sector\"],\n",
        "          \"target_clients\": input_3[\"target_clients\"],\n",
        "          \"resources\": input_3[\"resources\"],\n",
        "          \"strategic_priorities\": input_3[\"strategic_priorities\"],\n",
        "          \"project_name\": input_3[\"project_name\"],\n",
        "          \"challenge_description\": input_3[\"challenge_description\"],\n",
        "          \"purpose\": input_3[\"purpose\"],\n",
        "          \"focus_constraints\": input_3[\"focus_constraints\"]}"
      ],
      "metadata": {
        "id": "F0Vj228hRy8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opp_space_result = opp_spaces_crew.kickoff(inputs=inputs)\n"
      ],
      "metadata": {
        "id": "f6ZAorgdRkeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yP4nZJmC41N"
      },
      "outputs": [],
      "source": [
        "# Run crew\n",
        "\n",
        "# summaries= crew.kickoff(inputs=inputs)\n",
        "\n",
        "# Save the report to a file\n",
        "#write_to_file(summaries, directory='/content/drive/MyDrive/Creative_AI/research_engine/Outputs', filename='playground.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiGp0EqGqyoF"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GSzE56Jbkix"
      },
      "outputs": [],
      "source": [
        "my_insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "o7dUGtjvwc7k"
      },
      "outputs": [],
      "source": [
        "print(my_insights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57BWgROnwl0V"
      },
      "outputs": [],
      "source": [
        "print(type(my_insights))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}